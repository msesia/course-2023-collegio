{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom data generation models from the mfpi folder\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from mfpi import data_gen_models as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generating model\n",
    "\n",
    "We generate data from a toy model with one explanatory variable and one response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed for reproducibility\n",
    "np.random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a data-generating model from the following options (1, 2, 3, 4, or 5)\n",
    "data_model_index = 1\n",
    "\n",
    "if data_model_index==1:\n",
    "    # Linear model with homoscedastic errors\n",
    "    data_model = data.Model_Reg1()\n",
    "elif data_model_index==2:\n",
    "    # Linear model with heteroschedastic errors\n",
    "    data_model = data.Model_Reg2()\n",
    "elif data_model_index==3:\n",
    "    # Linear model with heavy-tail errors\n",
    "    data_model = data.Model_Reg3()\n",
    "elif data_model_index==4:\n",
    "    # Non-linear model with homoscedastic errors\n",
    "    data_model = data.Model_Reg4()\n",
    "elif data_model_index==5:\n",
    "    # Non-linear model with heteroschedastic errors\n",
    "    data_model = data.Model_Reg4(a=1)\n",
    "else:\n",
    "    print(\"Error: unknown data model\")\n",
    "    data_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate the labeled data\n",
    "n_data = 1000\n",
    "X_data, Y_data = data_model.sample(n_data)\n",
    "\n",
    "# Generate the test data\n",
    "n_test = 1000\n",
    "X_test, Y_test = data_model.sample(n_test)\n",
    "\n",
    "# Prepare to make side-to-side plots\n",
    "plt.figure(figsize=(12,3.5))\n",
    "\n",
    "# Plot histogram of Y values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(Y_data, alpha=0.5)\n",
    "plt.xlabel(\"Y\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Y values ({:d} observations)\".format(n_data))\n",
    "\n",
    "# Make scatter plot of the data\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_data[:,0], Y_data, alpha=0.5)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Data ({:d} observations)\".format(n_data))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warmup: Linear regression\n",
    "\n",
    "Let's see what happens if we try to apply linear regression to these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "\n",
    "# Fit a linear model with ordinary least squares\n",
    "linear_model = sm.OLS(Y_data,sm.add_constant(X_data)).fit()\n",
    "\n",
    "# Compute the regression function over a fine grid of x-values\n",
    "x_grid = np.linspace(0,1,1000)\n",
    "X_grid = np.reshape(x_grid, (len(x_grid),1))\n",
    "f_hat_linear = linear_model.predict(sm.add_constant(X_grid))\n",
    "\n",
    "# Plot the regression function\n",
    "plt.scatter(X_data[:,0], Y_data, alpha=0.5)\n",
    "plt.plot(x_grid, f_hat_linear, color=\"black\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Data and linear regression function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to use linear regression theory to compute prediction intervals.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal significance level (1 - coverage level)\n",
    "alpha = 0.1\n",
    "\n",
    "# Apply the fitted model to the grid of x values\n",
    "pred_grid = linear_model.get_prediction(sm.add_constant(X_grid)).summary_frame(alpha=alpha)\n",
    "pred_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the prediction bands over the grid of x-values\n",
    "linear_bands = np.array(pred_grid)[:,[4,5]]\n",
    "\n",
    "plt.scatter(X_data[:,0], Y_data, alpha=0.5)\n",
    "plt.plot(x_grid, f_hat_linear, color=\"black\")\n",
    "plt.plot(x_grid, linear_bands[:,0], color=\"red\")\n",
    "plt.plot(x_grid, linear_bands[:,1], color=\"red\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Training data and linear regression prediction bands (alpha: {:.2f})\".format(alpha))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct prediction intervals for all test points\n",
    "pred_test = linear_model.get_prediction(sm.add_constant(X_test)).summary_frame(alpha=alpha)\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_predictions(X_test, Y_test, lower, upper, show_plot=True):\n",
    "    covered = (Y_test>=lower) * (Y_test <= upper)\n",
    "    coverage = np.mean(covered)\n",
    "    width = np.mean(upper-lower)\n",
    "        \n",
    "    # Plot the prediction bands and compare them to the test data\n",
    "    if show_plot:\n",
    "        order = np.argsort(X_test[:,0])\n",
    "        plt.scatter(X_test[order,0], Y_test[order], alpha=0.5)\n",
    "        plt.plot(X_test[order,0], lower[order], color=\"red\")\n",
    "        plt.plot(X_test[order,0], upper[order], color=\"red\")\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Y\")\n",
    "        txt_subtitle = \"Coverage: {:.3f}, Average width: {:.3f}\".format(coverage, width)\n",
    "        plt.title(\"Test data and prediction bands (alpha: {:.2f})\\n\".format(alpha)+txt_subtitle)\n",
    "        plt.show()\n",
    "    \n",
    "    return coverage, width\n",
    "    \n",
    "# Evaluate the empirical coverage and the average width of the prediction bands\n",
    "lower = np.array(pred_test)[:,4]\n",
    "upper = np.array(pred_test)[:,5]    \n",
    "_, _ = eval_predictions(X_test, Y_test, lower, upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with a machine learning model\n",
    "\n",
    "We now fit a more sophisticated machine learning model on the training data.\n",
    "\n",
    "To learn more about the Python sklearn package: https://scikit-learn.org/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Choose a black-box machine learning model (1,2,3,4)\n",
    "bb_model_index = 1\n",
    "\n",
    "if bb_model_index==1:\n",
    "    # Random forest\n",
    "    black_box = RandomForestRegressor(n_estimators=100, min_samples_split=10, random_state=2023)\n",
    "elif bb_model_index==2:\n",
    "    # Random forest with more aggressive splits\n",
    "    black_box = RandomForestRegressor(n_estimators=100, min_samples_split=1, random_state=2023)\n",
    "elif bb_model_index==3:\n",
    "    # Support vector machine\n",
    "    black_box = SVR(kernel='rbf', degree=3)\n",
    "elif bb_model_index==4:\n",
    "    # Neural network\n",
    "    black_box = MLPRegressor(hidden_layer_sizes=(200,), max_iter=1000, random_state=2023)\n",
    "else:\n",
    "    print(\"Error: unknown machine learning model\")\n",
    "    black_box = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a random forest to the data\n",
    "black_box.fit(X_data, Y_data)\n",
    "\n",
    "# Plot the regression function\n",
    "f_hat = black_box.predict(X_grid)\n",
    "plt.scatter(X_data[:,0], Y_data, alpha=0.5)\n",
    "plt.plot(x_grid, f_hat, color=\"black\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Data and random forest regression function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we assess the uncertainty of the predictions? Let's look at the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals on data and test data\n",
    "residuals_data = Y_data - black_box.predict(X_data)\n",
    "residuals_test = Y_test - black_box.predict(X_test)\n",
    "\n",
    "# Plot the absolute residuals\n",
    "plt.figure(figsize=(12,3.5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(np.abs(residuals_data), alpha=0.5, bins=10)\n",
    "plt.xlabel(\"Absolute residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Training data\")\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.hist(np.abs(residuals_test), alpha=0.5, bins=10)\n",
    "plt.xlabel(\"Absolute residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Test data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuals on the test data tend to be larger than on the train data due to overfitting.\n",
    "\n",
    "Therefore, naively trusting the distribution of the residual on the training data would not give valid predictive inferences.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import mquantiles\n",
    "\n",
    "def naive_prediction_intervals(X, Y, X_test, black_box, alpha):\n",
    "    \"\"\"\n",
    "    Compute naive prediction bands based on the distribution of\n",
    "      residuals within the training data set\n",
    "      \n",
    "    Input\n",
    "    X         : n x p data matrix of explanatory variables\n",
    "    Y         : n x 1 vector of response variables\n",
    "    X_test    : n x p test data matrix of explanatory variables\n",
    "    black_box : sklearn model object with 'fit' and 'predict' methods\n",
    "    alpha     : 1 - target coverage level \n",
    "    \"\"\"\n",
    "    \n",
    "    # Output placeholder\n",
    "    lower = None\n",
    "    upper = None\n",
    "    \n",
    "    # Fit the black box model on the training data\n",
    "    black_box.fit(X, Y)\n",
    "    \n",
    "    # Compute residuals on the training data\n",
    "    residuals_calib = np.abs(Y - black_box.predict(X))\n",
    "    \n",
    "    # Compute suitable empirical quantile of absolute residuals\n",
    "    n_calib = len(Y)\n",
    "    level_adjusted = 1.0-alpha\n",
    "    Q_hat = mquantiles(residuals_calib, prob=level_adjusted)[0]\n",
    "    \n",
    "    # Construct prediction bands\n",
    "    Y_hat = black_box.predict(X_test)\n",
    "    lower = Y_hat - Q_hat\n",
    "    upper = Y_hat + Q_hat\n",
    "    \n",
    "    return lower, upper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired coverage level (1-alpha)\n",
    "alpha = 0.1\n",
    "\n",
    "# Apply split conformal\n",
    "lower_naive, upper_naive = naive_prediction_intervals(X_data, Y_data, X_test, black_box, alpha)\n",
    "\n",
    "# Evaluate the predictions\n",
    "_, _ = eval_predictions(X_test, Y_test, lower_naive, upper_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformal prediction\n",
    "\n",
    "Let's construct conformal prediction intervals.\n",
    "\n",
    "Hint: read about the function `train_test_split`: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def conformal_prediction_intervals(X, Y, X_test, black_box, alpha):\n",
    "    \"\"\"\n",
    "    Compute conformal prediction bands\n",
    "    \n",
    "    Input\n",
    "    X         : n x p data matrix of explanatory variables\n",
    "    Y         : n x 1 vector of response variables\n",
    "    X_test    : n x p test data matrix of explanatory variables\n",
    "    black_box : sklearn model object with 'fit' and 'predict' methods\n",
    "    alpha     : 1 - target coverage level \n",
    "    \"\"\"\n",
    "    \n",
    "    # Output placeholder\n",
    "    lower = None\n",
    "    upper = None\n",
    "    \n",
    "    # Split the data into training and calibration sets\n",
    "    X_train, X_calib, Y_train, Y_calib = train_test_split(X, Y, test_size=0.5, random_state=2023)\n",
    "    \n",
    "    # Fit the black box model on the training data\n",
    "    \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "    \n",
    "    # Compute residuals on the calibration data\n",
    "    \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "    \n",
    "    # Compute suitable empirical quantile of absolute residuals\n",
    "    \"\"\"TODO: write your code here (3 lines)\"\"\"\n",
    "    \n",
    "    # Construct prediction bands\n",
    "    \"\"\"TODO: write your code here (3 lines)\"\"\"\n",
    "    \n",
    "    return lower, upper  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired coverage level (1-alpha)\n",
    "alpha = 0.1\n",
    "\n",
    "# Apply split conformal\n",
    "lower, upper = conformal_prediction_intervals(X_data, Y_data, X_test, black_box, alpha)\n",
    "\n",
    "# Evaluate the predictions\n",
    "_, _ = eval_predictions(X_test, Y_test, lower, upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracle predictions\n",
    "\n",
    "Since we know the data generating model, we have access to oracle prediction intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_oracle, upper_oracle = data_model.oracle_predict(X_test, alpha)\n",
    "\n",
    "# Evaluate the predictions\n",
    "_, _ = eval_predictions(X_test, Y_test, lower_oracle, upper_oracle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile regression\n",
    "\n",
    "Let's now play fair and forget about the oracle.\n",
    "We will use a black-box quantile regression model instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom quantile regression models from the mfpi folder\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from mfpi import qr_models as qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a black-box quantile regression model (1 or 2)\n",
    "bb_qr_model_index = 1\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "if bb_qr_model_index==1:\n",
    "    # Random forest\n",
    "    black_box_qr = qr.LinearQR(alpha=0.1)\n",
    "elif bb_qr_model_index==2:\n",
    "    black_box_qr = qr.RFQR()\n",
    "else:\n",
    "    print(\"Error: unknown quantile regression model\")\n",
    "    black_box_qr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the quantile regression model\n",
    "black_box_qr.fit(X_data, Y_data)\n",
    "\n",
    "# Estimate conditional quantiles for data set\n",
    "lower_qr, upper_qr = black_box_qr.predict(X_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "_, _ = eval_predictions(X_test, Y_test, lower_qr, upper_qr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformalized quantile regression\n",
    "\n",
    "Since we don't want to blindly trust the black-box quantile regression model, we will use conformal inference to correct the prediction intervals.\n",
    "\n",
    "To learn more about quantile regression with random forests in Python: https://pypi.org/project/quantile-forest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def cqr_prediction_intervals(X, Y, X_test, black_box, alpha):\n",
    "    \"\"\"\n",
    "    Compute split-conformal quantile regression prediction bands.\n",
    "    Uses quantile random forests as a black box \n",
    "    \n",
    "    Input\n",
    "    X         : n x p data matrix of explanatory variables\n",
    "    Y         : n x 1 vector of response variables\n",
    "    X_test    : n x p test data matrix of explanatory variables\n",
    "    black_box : quantile regression model object with 'fit' and 'predict' methods\n",
    "    alpha     : 1 - target coverage level \n",
    "    \"\"\"\n",
    "    \n",
    "    # Output placeholder\n",
    "    lower = None\n",
    "    upper = None\n",
    "    \n",
    "    # Split the data into training and calibration sets\n",
    "    \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "    \n",
    "    # Fit the quantile regression model\n",
    "    \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "\n",
    "    # Estimate conditional quantiles for calibration set\n",
    "    \"\"\"TODO: write your code here (2 lines)\"\"\"\n",
    "    \n",
    "    # Compute conformity scores on the calibration data\n",
    "    \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "    \n",
    "    # Compute suitable empirical quantile of absolute residuals\n",
    "    \"\"\"TODO: write your code here (3 lines)\"\"\"\n",
    "    \n",
    "    # Construct prediction bands\n",
    "    \"\"\"TODO: write your code here (3 lines)\"\"\"\n",
    "    \n",
    "    return lower, upper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired coverage level (1-alpha)\n",
    "alpha = 0.1\n",
    "\n",
    "# Apply quantile regression split conformal\n",
    "lower_cqr, upper_cqr = cqr_prediction_intervals(X_data, Y_data, X_test, black_box_qr, alpha)\n",
    "\n",
    "# Evaluate the predictions\n",
    "_, _ = eval_predictions(X_test, Y_test, lower_cqr, upper_cqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
