{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import mquantiles\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom quantile regression models from the mfpi folder\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from mfpi import qr_models as qr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set\n",
    "\n",
    "In this workbook, we will use a real data set about car fuel efficiency.\n",
    "This dataset was taken from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/auto+mpg).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Download the Auto MPG Data Set\n",
    "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "col_names = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"year\", \"origin\", \"name\"]\n",
    "dataset = pd.read_fwf(data_url, names=col_names, na_values=\"?\")\n",
    "\n",
    "# Show data preview\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove rows with missing values and the last column, which is not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# Let's remove the car name column\n",
    "dataset = dataset.drop(['name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the analysis, let's convert the data set to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data frame to numpy array\n",
    "dataset = dataset.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a test set\n",
    "\n",
    "We consider the problem of predicting the fuel efficiency (miles per gallon) using the other variables.\n",
    "\n",
    "We will hold out some of the observations for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(2023)\n",
    "\n",
    "# Divide data\n",
    "X_data, X_test, Y_data, Y_test = train_test_split(dataset[:,1:-1], dataset[:,0], test_size=0.2, random_state=2023)\n",
    "\n",
    "print(\"Number of test data points: {:d}.\".format(len(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning predictions\n",
    "\n",
    "We can try to predict fuel efficiency using a random forest regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a random forest object\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "black_box = RandomForestRegressor(n_estimators=10, min_samples_split=5, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the black-box model on all data points\n",
    "black_box.fit(X_data, Y_data)\n",
    "\n",
    "# Make predictions on test data\n",
    "Y_hat = black_box.predict(X_test)\n",
    "\n",
    "# Compare test points to predicted values\n",
    "plt.plot([0, 45], [0, 45], color = 'black', linewidth = 1)\n",
    "plt.scatter(Y_test, Y_hat)\n",
    "plt.axis('square')\n",
    "plt.xlabel(\"True Y\")\n",
    "plt.ylabel(\"Predicted Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive prediction intervals based on in-sample residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_prediction_intervals(X, Y, X_test, black_box, alpha):\n",
    "    \"\"\"\n",
    "    Compute naive prediction bands based on the distribution of\n",
    "      residuals within the training data set\n",
    "      \n",
    "    Input\n",
    "    X         : n x p data matrix of explanatory variables\n",
    "    Y         : n x 1 vector of response variables\n",
    "    X_test    : n x p test data matrix of explanatory variables\n",
    "    black_box : sklearn model object with 'fit' and 'predict' methods\n",
    "    alpha     : 1 - target coverage level \n",
    "    \"\"\"\n",
    "    \n",
    "    # Output placeholder\n",
    "    lower = None\n",
    "    upper = None\n",
    "    \n",
    "    # Fit the black box model on the training data\n",
    "    black_box.fit(X, Y)\n",
    "    \n",
    "    # Compute residuals on the training data\n",
    "    residuals_calib = np.abs(Y - black_box.predict(X))\n",
    "    \n",
    "    # Compute suitable empirical quantile of absolute residuals\n",
    "    n_calib = len(Y)\n",
    "    level_adjusted = 1.0-alpha\n",
    "    Q_hat = mquantiles(residuals_calib, prob=level_adjusted)[0]\n",
    "    \n",
    "    # Construct prediction bands\n",
    "    Y_hat = black_box.predict(X_test)\n",
    "    lower = Y_hat - Q_hat\n",
    "    upper = Y_hat + Q_hat\n",
    "    \n",
    "    return lower, upper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(lower, upper, X, Y, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate performance metrics for a set of regression predictions\n",
    "    Computes:\n",
    "    - marginal coverage\n",
    "    - average size of sets\n",
    "    \n",
    "    Input\n",
    "    lower     : n x 1 vector of prediction lower bounds\n",
    "    upper     : n x 1 vector of prediction upper upper\n",
    "    X         : n x p data matrix of explanatory variables\n",
    "    Y         : n x 1 vector of response variables\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of samples\n",
    "    n = len(Y)\n",
    "    \n",
    "    # Evaluate the empirical coverage\n",
    "    covered = (Y>=lower) * (Y <= upper)\n",
    "\n",
    "    # Compute marginal coverage\n",
    "    marginal_coverage = np.mean(covered)\n",
    "    \n",
    "    # Compute average size of prediction sets\n",
    "    size = np.mean(upper-lower)\n",
    "    \n",
    "    # Compute average size of prediction sets that contain the true label\n",
    "    idx_cover = np.where(covered)[0]\n",
    "    size_cover = np.mean(upper[idx_cover]-lower[idx_cover])\n",
    "    \n",
    "    # Print summary\n",
    "    if verbose:\n",
    "        print('Marginal coverage       : {:2.3%}'.format(marginal_coverage))\n",
    "        print('Average length          : {:2.3f}'.format(size))\n",
    "        \n",
    "    return marginal_coverage, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired coverage level (1-alpha)\n",
    "alpha = 0.1\n",
    "\n",
    "# Apply split conformal\n",
    "lower, upper = naive_prediction_intervals(X_data, Y_data, X_test, black_box, alpha)\n",
    "\n",
    "# Evaluate the predictions\n",
    "metrics = evaluate_predictions(lower, upper, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformal prediction via conditional mean regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Choose a black-box machine learning model (1,2,3,4)\n",
    "bb_model_index = 1\n",
    "\n",
    "if bb_model_index==1:\n",
    "    # Random forest\n",
    "    black_box = RandomForestRegressor(n_estimators=10, min_samples_split=10, random_state=2023)\n",
    "elif bb_model_index==2:\n",
    "    # Random forest with more aggressive splits\n",
    "    black_box = RandomForestRegressor(n_estimators=10, min_samples_split=1, random_state=2023)\n",
    "elif bb_model_index==3:\n",
    "    # Support vector machine\n",
    "    black_box = SVR(kernel='rbf', degree=3)\n",
    "elif bb_model_index==4:\n",
    "    # Neural network\n",
    "    black_box = MLPRegressor(hidden_layer_sizes=(200,), max_iter=1000, random_state=2023)\n",
    "else:\n",
    "    print(\"Error: unknown machine learning model\")\n",
    "    black_box = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conformal_prediction_intervals(X, Y, X_test, black_box, alpha, random_state=2023):\n",
    "    \"\"\"\n",
    "    Compute conformal prediction bands\n",
    "    \n",
    "    Input\n",
    "    X         : n x p data matrix of explanatory variables\n",
    "    Y         : n x 1 vector of response variables\n",
    "    X_test    : n x p test data matrix of explanatory variables\n",
    "    black_box : sklearn model object with 'fit' and 'predict' methods\n",
    "    alpha     : 1 - target coverage level \n",
    "    \"\"\"\n",
    "    \n",
    "    # Output placeholder\n",
    "    lower = None\n",
    "    upper = None\n",
    "    \n",
    "    # Split the data into training and calibration sets\n",
    "    X_train, X_calib, Y_train, Y_calib = train_test_split(X, Y, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    # Fit the black box model on the training data\n",
    "    black_box.fit(X_train, Y_train)\n",
    "    \n",
    "    # Compute residuals on the calibration data\n",
    "    residuals_calib = np.abs(Y_calib - black_box.predict(X_calib))\n",
    "    \n",
    "    # Compute suitable empirical quantile of absolute residuals\n",
    "    n_calib = len(Y_calib)\n",
    "    level_adjusted = (1.0-alpha)*(1.0+1.0/float(n_calib))\n",
    "    Q_hat = mquantiles(residuals_calib, prob=level_adjusted)[0]\n",
    "    \n",
    "    # Construct prediction bands\n",
    "    Y_hat = black_box.predict(X_test)\n",
    "    lower = Y_hat - Q_hat\n",
    "    upper = Y_hat + Q_hat\n",
    "    \n",
    "    return lower, upper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired coverage level (1-alpha)\n",
    "alpha = 0.1\n",
    "\n",
    "# Apply split conformal\n",
    "lower, upper = conformal_prediction_intervals(X_data, Y_data, X_test, black_box, alpha)\n",
    "\n",
    "# Evaluate the predictions\n",
    "metrics = evaluate_predictions(lower, upper, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import copy\n",
    "\n",
    "def cv_prediction_intervals(X, Y, X_test, black_box, alpha, K, random_state=2023):\n",
    "    \"\"\"\n",
    "    Compute CV+ version of quantile regression prediction bands.\n",
    "    Uses quantile random forests as a black box \n",
    "    \n",
    "    Input\n",
    "    X            : n x p data matrix of explanatory variables\n",
    "    Y            : n x 1 vector of response variables\n",
    "    X_test       : n x p test data matrix of explanatory variables\n",
    "    black_box    : sklearn model object with 'fit' and 'predict' methods\n",
    "    alpha        : 1 - target coverage level \n",
    "    K            : number of folds\n",
    "    random_state : random seed for replicability (default: 2023)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of data points\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    # Number of test points\n",
    "    n_test = X_test.shape[0]\n",
    "    \n",
    "    # Split the data into K folds\n",
    "    cv = KFold(n_splits=K, random_state=random_state, shuffle=True)\n",
    "    \n",
    "    # Make list of test indices for each fold\n",
    "    calibration_indices = [calib_index for _, calib_index in cv.split(X)]\n",
    "    \n",
    "    # Make list of folds for each individual\n",
    "    # That is, fold[i] = k(i) in the notation from the slides\n",
    "    fold = np.zeros(n).astype(int)\n",
    "    for k in range(K):\n",
    "        fold[calibration_indices[k]] = k\n",
    "    \n",
    "    # Fit K models, one for each fold\n",
    "    q_hat = [ copy.deepcopy(black_box.fit(X[train_index], Y[train_index])) \n",
    "             for train_index, _ in cv.split(X) ]\n",
    "    \n",
    "    # Compute conformity scores on hold-out data for each fold\n",
    "    Z = np.zeros(len(Y))\n",
    "    for k in range(K):\n",
    "        \n",
    "        # List of calibration points for this fold\n",
    "        idx_calib = None # This should be a vector of indices corresponding to the hold-out points\n",
    "        \"\"\"TODO: write your code here (1 lines)\"\"\"\n",
    "        \n",
    "        # Evaluate point predictions for hold-out data\n",
    "        y_hat = None # This should be a vector of the same length as idx_calib\n",
    "        \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "        \n",
    "        # Compute conformity scores for this fold\n",
    "        Z_fold = None # This should be a vector of the same length as idx_calib\n",
    "        \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "        \n",
    "        # Store the conformity scores for this fold\n",
    "        Z[idx_calib] = Z_fold\n",
    "       \n",
    "    # Compute upper limit of prediction intervals for each test point (one at a time)\n",
    "    lower = np.zeros(n_test)\n",
    "    upper = np.zeros(n_test)\n",
    "        \n",
    "    for j in range(n_test):\n",
    "        # Evaluate point predictions for hold-out data\n",
    "        y_hat = np.zeros(n)\n",
    "        \n",
    "        for k in range(K):\n",
    "            # Which data points were hold-out in this fold?\n",
    "            idx_calib = None # This should be a vector of indices corresponding to the hold-out points\n",
    "            \"\"\"TODO: write your code here (1 lines)\"\"\"\n",
    "            \n",
    "            # Evaluate point predictions for hold-out data\n",
    "            y_hat = None # This should be a vector of the same length as idx_calib\n",
    "            \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "            \n",
    "        # CV+ upper limit for this point\n",
    "        upper[j] = None # This should be the upper limit of the prediction interval for test point j\n",
    "        \"\"\"TODO: write your code here (2 lines)\"\"\"\n",
    "        \n",
    "        # CV+ lower limit for this point\n",
    "        lower[j] = None # This should be the upper limit of the prediction interval for test point j\n",
    "        \"\"\"TODO: write your code here (2 lines)\"\"\"\n",
    "    \n",
    "    return lower, upper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply CV+\n",
    "K = 10\n",
    "lower, upper = cv_prediction_intervals(X_data, Y_data, X_test, black_box, alpha, K)\n",
    "\n",
    "# Evaluate performance\n",
    "metrics = evaluate_predictions(lower, upper, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical experiments\n",
    "\n",
    "We will now repeatedly apply the two methods described above to the data set, each time using a different random subset of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_cv(dataset, K, random_state=2023):\n",
    "    # Divide data\n",
    "    X_data, X_test, Y_data, Y_test = train_test_split(dataset[:,1:-1], dataset[:,0], \n",
    "                                                      test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    # Run and evaluate split conformal CQR\n",
    "    lower_sc, upper_sc = conformal_prediction_intervals(X_data, Y_data, X_test, black_box, alpha, random_state=random_state)\n",
    "    metrics_sc = evaluate_predictions(lower_sc, upper_sc, X_test, Y_test, verbose=False)\n",
    "    \n",
    "    # Run and evaluate CV+\n",
    "    lower_cv, upper_cv = cv_prediction_intervals(X_data, Y_data, X_test, black_box, alpha, K, random_state=random_state)\n",
    "    metrics_cv = evaluate_predictions(lower_cv, upper_cv, X_test, Y_test, verbose=False)\n",
    "    \n",
    "    # Return results\n",
    "    results_exp = pd.DataFrame({\"Method\":[\"Split\", \"CV+\"], \n",
    "                                \"Coverage\":[metrics_sc[0], metrics_cv[0]],\n",
    "                                \"Length\":[metrics_sc[1], metrics_cv[1]],\n",
    "                  })\n",
    "    return results_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run many experiments\n",
    "results_cv = pd.DataFrame()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for experiment in tqdm(range(50)):\n",
    "    \n",
    "    # Random state for this experiment\n",
    "    random_state = 2023 + experiment\n",
    "    \n",
    "    # Run the experiment\n",
    "    \n",
    "    result_exp = run_experiment_cv(dataset, K=10, random_state=random_state)\n",
    "    \n",
    "    # Store results\n",
    "    results_cv = pd.concat([results_cv,result_exp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Prepare to make side-to-side plots\n",
    "plt.figure(figsize=(12,3.5))\n",
    "\n",
    "# Compare marginal coverage\n",
    "plt.subplot(1, 2, 1)\n",
    "ax = sns.boxplot(y=\"Coverage\", x=\"Method\", hue=\"Method\", data=results_cv)\n",
    "ax.set(xlabel='Method', ylabel='Marginal coverage')\n",
    "ax.axhline(1-alpha, ls='--', color=\"red\")\n",
    "\n",
    "# Compare average length of prediction intervals\n",
    "plt.subplot(1, 2, 2)\n",
    "ax = sns.boxplot(y=\"Length\", x=\"Method\", hue=\"Method\", data=results_cv)\n",
    "ax.set(xlabel='Method', ylabel='Size of prediction intervals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformal prediction via quantile regression\n",
    "\n",
    "Alternatively, we already know how to construct predictive intervals with valid marginal coverage using CQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a black-box quantile regression model (1 or 2)\n",
    "bb_qr_model_index = 2\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "if bb_qr_model_index==1:\n",
    "    # Random forest\n",
    "    black_box_qr = qr.LinearQR(alpha=0.1)\n",
    "elif bb_qr_model_index==2:\n",
    "    black_box_qr = qr.RFQR(alpha=0.1, n_estimators=10)\n",
    "else:\n",
    "    print(\"Error: unknown quantile regression model\")\n",
    "    black_box_qr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cqr_prediction_intervals(X, Y, X_test, black_box, alpha, random_state=2023):\n",
    "    \"\"\"\n",
    "    Compute split-conformal quantile regression prediction bands.\n",
    "    Uses quantile random forests as a black box \n",
    "    \n",
    "    Input\n",
    "    X         : n x p data matrix of explanatory variables\n",
    "    Y         : n x 1 vector of response variables\n",
    "    X_test    : n x p test data matrix of explanatory variables\n",
    "    black_box : quantile regression model object with 'fit' and 'predict' methods\n",
    "    alpha     : 1 - target coverage level \n",
    "    \"\"\"\n",
    "    \n",
    "    # Output placeholder\n",
    "    lower = None\n",
    "    upper = None\n",
    "    \n",
    "    # Split the data into training and calibration sets\n",
    "    X_train, X_calib, Y_train, Y_calib = train_test_split(X, Y, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    # Fit the quantile regression model\n",
    "    black_box.fit(X_train, Y_train)\n",
    "\n",
    "    # Estimate conditional quantiles for calibration set\n",
    "    lower, upper = black_box.predict(X_calib)\n",
    "    \n",
    "    # Compute conformity scores on the calibration data\n",
    "    residuals_calib = np.maximum(Y_calib - upper, lower - Y_calib)\n",
    "    \n",
    "    # Compute suitable empirical quantile of absolute residuals\n",
    "    n_calib = len(Y_calib)\n",
    "    level_adjusted = (1.0-alpha)*(1.0+1.0/float(n_calib))\n",
    "    Q_hat = mquantiles(residuals_calib, prob=level_adjusted)[0]\n",
    "    \n",
    "    # Construct prediction bands\n",
    "    lower, upper = black_box.predict(X_test)\n",
    "    lower = lower - Q_hat\n",
    "    upper = upper + Q_hat\n",
    "    \n",
    "    return lower, upper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired coverage level (1-alpha)\n",
    "alpha = 0.1\n",
    "\n",
    "# Apply quantile regression split conformal\n",
    "lower, upper = cqr_prediction_intervals(X_data, Y_data, X_test, black_box_qr, alpha)\n",
    "\n",
    "# Evaluate performance of predictions\n",
    "metrics = evaluate_predictions(lower, upper, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV+ conformal quantile regression (optional homework)\n",
    "\n",
    "Next, we will apply CQR with CV+ data hold out instead of split-conformal.\n",
    "This is slighly more involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import copy\n",
    "\n",
    "def cv_cqr_prediction_intervals(X, Y, X_test, alpha, K, random_state=2023):\n",
    "    \"\"\"\n",
    "    Compute CV+ version of quantile regression prediction bands.\n",
    "    Uses quantile random forests as a black box \n",
    "    \n",
    "    Input\n",
    "    X            : n x p data matrix of explanatory variables\n",
    "    Y            : n x 1 vector of response variables\n",
    "    X_test       : n x p test data matrix of explanatory variables\n",
    "    alpha        : 1 - target coverage level \n",
    "    K            : number of folds\n",
    "    random_state : random seed for replicability (default: 2023)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of data points\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    # Number of test points\n",
    "    n_test = X_test.shape[0]\n",
    "    \n",
    "    # Split the data into K folds\n",
    "    cv = KFold(n_splits=K, random_state=random_state, shuffle=True)\n",
    "    \n",
    "    # Make list of test indices for each fold\n",
    "    calibration_indices = [calib_index for _, calib_index in cv.split(X)]\n",
    "    \n",
    "    # Make list of folds for each individual\n",
    "    # That is, fold[i] = k(i) in the notation from the slides\n",
    "    fold = np.zeros(n).astype(int)\n",
    "    for k in range(K):\n",
    "        fold[calibration_indices[k]] = k\n",
    "    \n",
    "    # Fit K models, one for each fold\n",
    "    q_hat = None # This should be a list of K properly trained black-box objects\n",
    "    \"\"\"TODO: write your code here (2 lines)\"\"\"\n",
    "    \n",
    "    # Compute conformity scores on hold-out data for each fold\n",
    "    Z = np.zeros(len(Y))\n",
    "    for k in range(K):\n",
    "        \n",
    "        # List of calibration points for this fold\n",
    "        idx_calib = None # This should be a vector of indices corresponding to the hold-out points\n",
    "        \"\"\"TODO: write your code here (1 lines)\"\"\"\n",
    "        \n",
    "        # Evaluate hold-out estimates of lower and upper conditional quantiles\n",
    "        lower_estim = None # This should be a vector of the same length as idx_calib\n",
    "        upper_estim = None # This should be a vector of the same length as idx_calib\n",
    "        \"\"\"TODO: write your code here (2 lines)\"\"\"\n",
    "        \n",
    "        # Compute conformity scores for this fold\n",
    "        Z_fold = None # This should be a vector of the same length as idx_calib\n",
    "        \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "        \n",
    "        # Store the conformity scores for this fold\n",
    "        Z[idx_calib] = Z_fold\n",
    "       \n",
    "    # Compute upper limit of prediction intervals for each test point (one at a time)\n",
    "    lower = np.zeros(n_test)\n",
    "    upper = np.zeros(n_test)\n",
    "        \n",
    "    for j in range(n_test):\n",
    "        # Evaluate estimates of conditional quantiles\n",
    "        lower_estim = np.zeros(n)\n",
    "        upper_estim = np.zeros(n)\n",
    "        \n",
    "        for k in range(K):\n",
    "            # Which data points were hold-out in this fold?\n",
    "            idx_calib = None # This should be a vector of indices corresponding to the hold-out points\n",
    "            \"\"\"TODO: write your code here (1 lines)\"\"\"\n",
    "            \n",
    "            # Evaluate hold-out estimates of lower and upper conditional quantiles\n",
    "            lower_estim = None # This should be a vector of the same length as idx_calib\n",
    "            upper_estim = None # This should be a vector of the same length as idx_calib\n",
    "            \"\"\"TODO: write your code here (2 lines)\"\"\"\n",
    "            \n",
    "        # CV+ upper limit for this point\n",
    "        upper[j] = None # This should be the upper limit of the prediction interval for test point j\n",
    "        \"\"\"TODO: write your code here (2 lines)\"\"\"\n",
    "        \n",
    "        # CV+ lower limit for this point\n",
    "        lower[j] = None # This should be the upper limit of the prediction interval for test point j\n",
    "        \"\"\"TODO: write your code here (2 lines)\"\"\"\n",
    "    \n",
    "    return lower, upper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply quantile regression with CV+\n",
    "K = 10\n",
    "lower, upper = cv_cqr_prediction_intervals(X_data, Y_data, X_test, alpha, K)\n",
    "\n",
    "# Evaluate performance\n",
    "metrics = evaluate_predictions(lower, upper, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical experiments (quantile regression)\n",
    "\n",
    "We will now repeatedly apply the two methods described above to the data set, each time using a different random subset of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(dataset, K, random_state=2023):\n",
    "    # Divide data\n",
    "    X_data, X_test, Y_data, Y_test = train_test_split(dataset[:,1:-1], dataset[:,0], \n",
    "                                                      test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    # Run and evaluate split conformal CQR\n",
    "    lower_sc, upper_sc = cqr_prediction_intervals(X_data, Y_data, X_test, black_box_qr, alpha, random_state=random_state)\n",
    "    metrics_sc = evaluate_predictions(lower_sc, upper_sc, X_test, Y_test, verbose=False)\n",
    "    \n",
    "    # Run and evaluate CV+ CQR\n",
    "    lower_cv, upper_cv = cv_cqr_prediction_intervals(X_data, Y_data, X_test, alpha, K, random_state=random_state)\n",
    "    metrics_cv = evaluate_predictions(lower_cv, upper_cv, X_test, Y_test, verbose=False)\n",
    "    \n",
    "    # Return results\n",
    "    results_exp = pd.DataFrame({\"Method\":[\"Split\", \"CV+\"], \n",
    "                                \"Coverage\":[metrics_sc[0], metrics_cv[0]],\n",
    "                                \"Length\":[metrics_sc[1], metrics_cv[1]],\n",
    "                  })\n",
    "    return results_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run many experiments\n",
    "results = pd.DataFrame()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for experiment in tqdm(range(50)):\n",
    "    \n",
    "    # Random state for this experiment\n",
    "    random_state = 2023 + experiment\n",
    "    \n",
    "    # Run the experiment\n",
    "    \n",
    "    result_exp = run_experiment(dataset, K=10, random_state=random_state)\n",
    "    \n",
    "    # Store results\n",
    "    results = pd.concat([results,result_exp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to make side-to-side plots\n",
    "plt.figure(figsize=(12,3.5))\n",
    "\n",
    "# Compare marginal coverage\n",
    "plt.subplot(1, 2, 1)\n",
    "ax = sns.boxplot(y=\"Coverage\", x=\"Method\", hue=\"Method\", data=results)\n",
    "ax.set(xlabel='Method', ylabel='Marginal coverage')\n",
    "ax.axhline(1-alpha, ls='--', color=\"red\")\n",
    "\n",
    "# Compare average length of prediction intervals\n",
    "plt.subplot(1, 2, 2)\n",
    "ax = sns.boxplot(y=\"Length\", x=\"Method\", hue=\"Method\", data=results)\n",
    "ax.set(xlabel='Method', ylabel='Size of prediction intervals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
